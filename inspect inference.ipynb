{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from encoder import Encoder\n",
    "from attention import Attention\n",
    "from decoder import Decoder\n",
    "from generator import Generator\n",
    "\n",
    "from data_loader import SpeechDataset, Padding, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels_dict.json', 'r') as f:\n",
    "    labels = json.loads(f.read())\n",
    "    \n",
    "id2label = {v: k for k, v in labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNAL_INPUT_SIZE = 1500 \n",
    "TXT_INPUT_SIZE = 135\n",
    "OUTPUT_DIM = 33\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "audio_conf = {'window': 'hamming',\n",
    "              'window_size' : 0.02,\n",
    "              'window_stride' : 0.01,\n",
    "              'sampling_rate': 16000}\n",
    "\n",
    "val_dataset = SpeechDataset('../../SpeechRecognition.EN/deepspeech.cv/data/cv-other-dev_manifest.csv', \n",
    "                            'labels_dict.json',\n",
    "                            audio_conf,\n",
    "                            transform=transforms.Compose([Padding(SIGNAL_INPUT_SIZE, TXT_INPUT_SIZE, 'labels_dict.json')]) \n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GRU = 6\n",
    "FEATURE = 161\n",
    "ENC_HID_DIM = 256\n",
    "DEC_HID_DIM = 256 \n",
    "DEC_EMB_DIM = 256\n",
    "DROPOUT_RATE = 0.0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "encoder = Encoder(FEATURE, NUM_GRU, ENC_HID_DIM, DEC_HID_DIM, DROPOUT_RATE, device)\n",
    "attention = Attention(enc_hid_dim=ENC_HID_DIM, dec_hid_dim=DEC_HID_DIM)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DROPOUT_RATE, attention)\n",
    "model = Generator(encoder, decoder, device).to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, txt_ids = torch.from_numpy(val_dataset[2]['signal']), torch.from_numpy(val_dataset[2]['transcript'])\n",
    "signal = signal.type(torch.FloatTensor).to(device)\n",
    "signal = signal.permute(1, 0)\n",
    "txt_ids = txt_ids.type(torch.LongTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.size(), txt_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('models/rsr_gan.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, output = model(signal.view(1, 1500, 161), txt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.max(2)[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_txt = ''\n",
    "for l in output.max(2)[1][0].cpu().numpy():\n",
    "    out_txt += id2label[l] \n",
    "    \n",
    "out_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_txt = ''\n",
    "for l in txt_ids[0].cpu().numpy():\n",
    "    true_txt += id2label[l]\n",
    "    \n",
    "true_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
