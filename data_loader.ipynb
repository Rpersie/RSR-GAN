{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDataset(Dataset):\n",
    "    \"\"\"Speech dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, labels_file, audio_conf, transform=None, normalize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file contain audio and transcript path.\n",
    "            labels_file (string): Path to the json file contain label dictionary.\n",
    "            audio_conf (dict) : Audio config info.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.speech_frame = pd.read_csv(csv_file, header=None)\n",
    "        with open(labels_file, 'r') as f:\n",
    "            self.labels = json.loads(f.read())\n",
    "        self.window = audio_conf['window']\n",
    "        self.window_size = audio_conf['window_size']\n",
    "        self.window_stride = audio_conf['window_stride']\n",
    "        self.sampling_rate = audio_conf['sampling_rate']\n",
    "        self.transform = transform\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.speech_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav_file = self.speech_frame.iloc[idx, 0]\n",
    "        transcript_file = self.speech_frame.iloc[idx, 1]\n",
    "        try:\n",
    "            signal, _ = sf.read(wav_file)\n",
    "            signal /= 1 << 31\n",
    "            signal = self.spectrogram(signal)\n",
    "\n",
    "            with open(transcript_file, 'r') as f:\n",
    "                transcript = f.read().strip()\n",
    "            transcript_idx = []\n",
    "            transcript_idx.append(self.labels['<sos>'])\n",
    "            for char in list(transcript):\n",
    "                if char in self.labels:\n",
    "                    transcript_idx.append(self.labels[char])\n",
    "            transcript_idx.append(self.labels['<eos>'])\n",
    "            sample = {'signal': signal, 'transcript': np.array(transcript_idx)}\n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "\n",
    "            return sample\n",
    "        except:\n",
    "            return wav_file\n",
    "    \n",
    "    def spectrogram(self, signal):\n",
    "        n_fft = int(self.sampling_rate * self.window_size)\n",
    "        win_length = n_fft\n",
    "        hop_length = int(self.sampling_rate * self.window_stride)\n",
    "        # STFT\n",
    "        D = librosa.stft(signal, n_fft=n_fft, hop_length=hop_length,\n",
    "                        window=self.window, win_length=win_length)\n",
    "        spect, phase = librosa.magphase(D)\n",
    "        # S = log(S+1)\n",
    "        spect = np.log1p(spect)\n",
    "        spect = torch.FloatTensor(spect)\n",
    "        if self.normalize:\n",
    "            mean = spect.mean()\n",
    "            std = spect.std()\n",
    "            spect.add_(-mean)\n",
    "            spect.div_(std)\n",
    "            \n",
    "        return spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Padding(object):\n",
    "    \"\"\"Rescale the audio signal and transcript to a given size.\n",
    "\n",
    "    Args:\n",
    "        signal_size (int): Desired output size of signal.\n",
    "        transcript_size (int): Desired output size of transcript.\n",
    "        labels_file (string): Path to the json file contain label dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, signal_size, transcript_size, labels_file):\n",
    "        assert isinstance(signal_size, (int))\n",
    "        assert isinstance(transcript_size, (int))\n",
    "        self.signal_size = signal_size\n",
    "        self.transcript_size = transcript_size\n",
    "        with open(labels_file, 'r') as f:\n",
    "            self.labels = json.loads(f.read())\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        signal, transcript = sample['signal'], sample['transcript']\n",
    "        signal /= 1 << 31\n",
    "        signal = pad_sequences(signal, \n",
    "                               maxlen=self.signal_size, padding='post', \n",
    "                               truncating='post', value=0.0, dtype='float')\n",
    "        transcript = pad_sequences(transcript.reshape(1, -1), \n",
    "                               maxlen=self.transcript_size, padding='post', \n",
    "                               truncating='post', value=self.labels['pad'], dtype='int')\n",
    "        \n",
    "        return {'signal': signal, 'transcript': transcript}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        signal, transcript = sample['signal'], sample['transcript']\n",
    "\n",
    "        return {'signal': torch.from_numpy(signal),\n",
    "                'transcript': torch.from_numpy(transcript)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
