{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from encoder import Encoder\n",
    "from attention import Attention\n",
    "from decoder import Decoder\n",
    "from generator import Generator\n",
    "\n",
    "from data_loader import SpeechDataset, Padding, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('labels_dict.json', 'r') as f:\n",
    "    labels = json.loads(f.read())\n",
    "    \n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNAL_INPUT_SIZE = 1500 \n",
    "TXT_INPUT_SIZE = 135\n",
    "OUTPUT_DIM = 33\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "audio_conf = {'window': 'hamming',\n",
    "              'window_size' : 0.02,\n",
    "              'window_stride' : 0.01,\n",
    "              'sampling_rate': 16000}\n",
    "\n",
    "train_dataset = SpeechDataset('../../SpeechRecognition.EN/deepspeech.cv/data/cv-valid-dev_manifest.csv', \n",
    "                            'labels_dict.json',\n",
    "                            audio_conf,\n",
    "                            transform=transforms.Compose([Padding(SIGNAL_INPUT_SIZE, TXT_INPUT_SIZE, 'labels_dict.json')]) \n",
    "                              )\n",
    "\n",
    "val_dataset = SpeechDataset('../../SpeechRecognition.EN/deepspeech.cv/data/cv-other-dev_manifest.csv', \n",
    "                            'labels_dict.json',\n",
    "                            audio_conf,\n",
    "                            transform=transforms.Compose([Padding(SIGNAL_INPUT_SIZE, TXT_INPUT_SIZE, 'labels_dict.json')]) \n",
    "                              )\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                            shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                            shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE = 161\n",
    "NUM_GRU = 6\n",
    "ENC_HID_DIM = 256\n",
    "DEC_HID_DIM = 256 \n",
    "DEC_EMB_DIM = 256\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "encoder = Encoder(FEATURE, NUM_GRU, ENC_HID_DIM, DEC_HID_DIM, DROPOUT_RATE, device)\n",
    "attention = Attention(enc_hid_dim=ENC_HID_DIM, dec_hid_dim=DEC_HID_DIM)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DROPOUT_RATE, attention)\n",
    "model = Generator(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if model.cuda:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "pad_idx = labels['pad']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()#ignore_index=pad_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, sample in tqdm(enumerate(iterator)):\n",
    "        \n",
    "        src = sample['signal'].type(torch.FloatTensor).to(device)\n",
    "        src = src.permute(0, 2, 1)\n",
    "        trg = sample['transcript'].type(torch.LongTensor).to(device)\n",
    "        trg = trg.view(-1, TXT_INPUT_SIZE)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #print('src.size - ', src.size(), ' trg.size - ', trg.size())\n",
    "        #print(trg[:, 0])\n",
    "        _, _, output = model(src, trg)\n",
    "        #print('src.size - ', src.size(), ' trg.size - ', trg.size(), ' output.size - ', output.size())\n",
    "        \n",
    "        loss = criterion(output.view(-1, output.shape[2]), trg.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    #print('in evaluation')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, sample in tqdm(enumerate(iterator)):\n",
    "\n",
    "            src = sample['signal'].type(torch.FloatTensor).to(device)\n",
    "            src = src.permute(0, 2, 1)\n",
    "            trg = sample['transcript'].type(torch.LongTensor).to(device)\n",
    "            trg = trg.view(-1, TXT_INPUT_SIZE)\n",
    "\n",
    "            _, _, output = model(src, trg, 0) #turn off teacher forcing\n",
    "            #print('output - ', output)\n",
    "            \n",
    "            loss = criterion(output.view(-1, output.shape[2]), trg.view(-1))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "385it [15:06,  2.40s/it]"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 25\n",
    "CLIP = 10\n",
    "SAVE_DIR = 'models'\n",
    "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'rsr_gan.pt')\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "if not os.path.isdir(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    with torch.cuda.device(1):\n",
    "        train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "        valid_loss = evaluate(model, val_dataloader, criterion)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print('Saved Model.')\n",
    "\n",
    "        print('Epoch: ', epoch+1, '| Train Loss: ', train_loss, '| Train PPL: ', math.exp(train_loss),\n",
    "              '| Val. Loss: ', valid_loss, '| Val. PPL: ', math.exp(valid_loss))\n",
    "    \n",
    "    #print('Train loss - ', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
